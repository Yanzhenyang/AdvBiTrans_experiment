{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout,concatenate,Flatten,Conv1D, MaxPooling1D,Conv2D, MaxPooling2D,Reshape,Input,Convolution1D,Activation,concatenate,SimpleRNN\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score  \n",
    "from tensorflow.keras import layers \n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mult_data = pd.read_csv('./Data/pccs_julei_54.csv')\n",
    "Mult_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = Mult_data.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Mult_data['Unnamed: 0']  # 删除'Unnamed: 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mult_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Mult_data.drop(columns=['class'],axis=1)\n",
    "Y = Mult_data['class']\n",
    "\n",
    "scaler = StandardScaler()   \n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.20, random_state=50)\n",
    "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算Accuary,F1等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(y_test,y_pred_labels):\n",
    "    \n",
    "    # Convert y_test to label indices if it's in One-Hot format\n",
    "    if y_test.ndim > 1:\n",
    "        y_test_labels = np.argmax(y_test, axis=1)\n",
    "    else:\n",
    "        y_test_labels = y_test\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    precision = precision_score(y_test_labels, y_pred_labels, average='macro')\n",
    "    recall = recall_score(y_test_labels, y_pred_labels, average='macro')\n",
    "    f1 = f1_score(y_test_labels, y_pred_labels, average='macro')\n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model_performance(y_test, y_pred_labels):\n",
    "    \n",
    "    # Convert y_test to label indices if it's in One-Hot format\n",
    "    if y_test.ndim > 1:\n",
    "        y_test_labels = np.argmax(y_test, axis=1)\n",
    "    else:\n",
    "        y_test_labels = y_test\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    precision = precision_score(y_test_labels, y_pred_labels, average=None)\n",
    "    recall = recall_score(y_test_labels, y_pred_labels, average=None)\n",
    "    f1 = f1_score(y_test_labels, y_pred_labels, average=None)\n",
    "\n",
    "    # Print overall metrics\n",
    "    print(f\"Overall Accuracy: {accuracy}\")\n",
    "    print(f\"Overall Precision (Macro Average): {np.mean(precision):.4f}\")\n",
    "    print(f\"Overall Recall (Macro Average): {np.mean(recall):.4f}\")\n",
    "    print(f\"Overall F1 Score (Macro Average): {np.mean(f1):.4f}\")\n",
    "\n",
    "    # Print metrics for each class\n",
    "    for i in range(len(precision)):\n",
    "        print(f\"\\nMetrics for Class {i}:\")\n",
    "        print(f\"Accuracy: {accuracy}\")  # Accuracy is overall, not per-class\n",
    "        print(f\"Precision: {precision[i]:.4f}\")\n",
    "        print(f\"Recall: {recall[i]:.4f}\")\n",
    "        print(f\"F1 Score: {f1[i]:.4f}\")\n",
    "\n",
    "# Example usage\n",
    "# y_test = [actual labels]\n",
    "# y_pred_labels = [predicted labels]\n",
    "# evaluate_model_performance(y_test, y_pred_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算FPR,FDR,FOR,FNR函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_multiclass(y_true, y_pred, num_classes):\n",
    "    # 初始化指标总和\n",
    "    total_fpr, total_fdr, total_for, total_fnr = 0, 0, 0, 0\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        y_true_binary = (y_true == cls).astype(int)\n",
    "        y_pred_binary = (y_pred == cls).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_binary, y_pred_binary).ravel()\n",
    "\n",
    "        FPR = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        FDR = fp / (fp + tp) if (fp + tp) > 0 else 0\n",
    "        FOR = fn / (fn + tn) if (fn + tn) > 0 else 0\n",
    "        FNR = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "\n",
    "        total_fpr += FPR\n",
    "        total_fdr += FDR\n",
    "        total_for += FOR\n",
    "        total_fnr += FNR\n",
    "\n",
    "    # 计算平均值\n",
    "    avg_fpr = total_fpr / num_classes\n",
    "    avg_fdr = total_fdr / num_classes\n",
    "    avg_for = total_for / num_classes\n",
    "    avg_fnr = total_fnr / num_classes\n",
    "\n",
    "    # 打印整体指标\n",
    "    print(f\"Overall FPR: {avg_fpr}\")\n",
    "    print(f\"Overall FDR: {avg_fdr}\")\n",
    "    print(f\"Overall FOR: {avg_for}\")\n",
    "    print(f\"Overall FNR: {avg_fnr}\")\n",
    "    \n",
    "    return avg_fpr, avg_fdr, avg_for, avg_fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算TNR,MCC,NPV函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def calculate_multiclass_tnr_mcc_npv(y_true, y_pred, num_classes):\n",
    "    total_tnr, total_mcc, total_npv = 0, 0, 0\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        y_true_binary = (y_true == cls).astype(int)\n",
    "        y_pred_binary = (y_pred == cls).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true_binary, y_pred_binary).ravel()\n",
    "\n",
    "        TNR = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        NPV = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "        denominator = sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "        MCC = (tp * tn - fp * fn) / denominator if denominator != 0 else 0\n",
    "\n",
    "        total_tnr += TNR\n",
    "        total_mcc += MCC\n",
    "        total_npv += NPV\n",
    "\n",
    "    avg_tnr = total_tnr / num_classes\n",
    "    avg_mcc = total_mcc / num_classes\n",
    "    avg_npv = total_npv / num_classes\n",
    "\n",
    "    # 打印整体指标\n",
    "    print(f\"Overall TNR: {avg_tnr}\")\n",
    "    print(f\"Overall MCC: {avg_mcc}\")\n",
    "    print(f\"Overall NPV: {avg_npv}\")\n",
    "\n",
    "    return avg_tnr, avg_mcc, avg_npv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, color, title, save_path):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    labels = [\"Beigen\", \"Mirai\", \"Gafgyt\"]  # Customize as needed\n",
    "    sns.heatmap(cm, annot=True, cmap=color, fmt=\"d\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted labels\")\n",
    "    plt.ylabel(\"True labels\")\n",
    "    plt.title(title, fontweight='bold', fontsize=12)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 绘制ROC曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def plot_multiclass_roc(y_true, y_score, num_classes, color, title, save_path):\n",
    "    \"\"\"\n",
    "    Plot and save a multi-class ROC curve without showing 'area' in the legend, \n",
    "    but instead showing the AUC score for each class.\n",
    "    \n",
    "    Args:\n",
    "    y_true (numpy.ndarray): True labels.\n",
    "    y_score (numpy.ndarray): Predicted scores or probabilities.\n",
    "    num_classes (int): Number of classes.\n",
    "    title (str): Title of the plot.\n",
    "    color (str): Color of the micro-average ROC curve.\n",
    "    save_path (str): Path to save the plot.\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Binarize the true labels\n",
    "    y_true = label_binarize(y_true, classes=range(num_classes))\n",
    "    figsize = (6, 4)\n",
    "    \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='Grand Average of all classes-(AUC = {0:0.4f})'.format(roc_auc[\"micro\"]),\n",
    "             color=color, linestyle=':', linewidth=4)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2,\n",
    "                 label='ROC curve of Class {0} AUC = {1:0.4f}'.format(i, roc_auc[i]))  # Changed label here\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title, fontweight='bold', fontsize=12)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULT_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 对目标变量进行编码\n",
    "encoder = LabelEncoder()\n",
    "encoded_Y = encoder.fit_transform(y_train)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "encoded_Y_test = encoder.transform(y_test)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy import stats\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 重塑训练和测试集 (LSTM需要3D输入)\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 构建模型（只构建一次）\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(64), input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model((X_train.shape[1], 1), num_classes=dummy_y_train.shape[1])\n",
    "\n",
    "# 5折交叉验证评估 (在训练集上)\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "num_classes = dummy_y_train.shape[1]\n",
    "\n",
    "# 保存每一类的指标\n",
    "acc_per_class = [[] for _ in range(num_classes)]\n",
    "prec_per_class = [[] for _ in range(num_classes)]\n",
    "recall_per_class = [[] for _ in range(num_classes)]\n",
    "f1_per_class = [[] for _ in range(num_classes)]\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train_reshaped, dummy_y_train):\n",
    "    X_tr, X_val = X_train_reshaped[train_idx], X_train_reshaped[val_idx]\n",
    "    y_tr, y_val = dummy_y_train[train_idx], dummy_y_train[val_idx]\n",
    "\n",
    "    # 每次都继续训练，不重置模型\n",
    "    model.fit(X_tr, y_tr, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_pred_classes = np.argmax(val_pred, axis=1)\n",
    "    y_val_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "    # 分类报告\n",
    "    report = classification_report(y_val_classes, val_pred_classes, output_dict=True, zero_division=0)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        label = str(i)\n",
    "        acc = report[label]['precision'] * report[label]['recall']  # 简单近似Acc per class\n",
    "        prec = report[label]['precision']\n",
    "        recall = report[label]['recall']\n",
    "        f1 = report[label]['f1-score']\n",
    "\n",
    "        acc_per_class[i].append(acc)\n",
    "        prec_per_class[i].append(prec)\n",
    "        recall_per_class[i].append(recall)\n",
    "        f1_per_class[i].append(f1)\n",
    "\n",
    "# 统计每一类的交叉验证结果\n",
    "def summarize_per_class(scores, name):\n",
    "    for idx, class_scores in enumerate(scores):\n",
    "        mean = np.mean(class_scores)\n",
    "        std = np.std(class_scores)\n",
    "        conf_interval = stats.t.interval(0.95, len(class_scores)-1, loc=mean, scale=stats.sem(class_scores))\n",
    "        print(f\"Class {idx} {name}: Mean={mean:.4f}, Std={std:.4f}, 95% CI=({conf_interval[0]:.4f}, {conf_interval[1]:.4f})\")\n",
    "\n",
    "print(\"\\n5折交叉验证结果 (每类):\")\n",
    "summarize_per_class(acc_per_class, \"Accuracy\")\n",
    "summarize_per_class(prec_per_class, \"Precision\")\n",
    "summarize_per_class(recall_per_class, \"Recall\")\n",
    "summarize_per_class(f1_per_class, \"F1-Score\")\n",
    "\n",
    "# 最后在独立测试集上评估\n",
    "print(\"\\n独立测试集评估:\")\n",
    "y_pred_test = model.predict(X_test_reshaped)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_test_classes = np.argmax(dummy_y_test, axis=1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_classes, y_pred_test_classes))\n",
    "print(classification_report(y_test_classes, y_pred_test_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(y_test_classes, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算指标\n",
    "num_classes = 3  # 假设有 3 个类别\n",
    "avg_fpr, avg_fdr, avg_for, avg_fnr = calculate_metrics_multiclass(y_test_classes, y_pred_classes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tnr, avg_mcc, avg_npv = calculate_multiclass_tnr_mcc_npv(y_test_classes, y_pred_classes, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test_classes, y_pred_classes, \"Reds\",\"BiLSTM\",\"./Picture/BiLSTM_juzehn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_test_classes, y_pred , num_classes, \"red\",\"BiLSTM\",\"./Picture/BiLSTM_ROC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Reshape, Dense, Dropout, Flatten\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# 定义5折交叉验证\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 保存每一折的指标\n",
    "acc_per_fold = []\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "f1_per_fold = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train, y_train):\n",
    "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "    y_tr, y_val = dummy_y_train[train_idx], dummy_y_train[val_idx]\n",
    "\n",
    "    # 定义模型输入\n",
    "    input_layer = Input(shape=(X_tr.shape[1],))\n",
    "    reshaped_input = Reshape((X_tr.shape[1], 1))(input_layer)\n",
    "    transformer_block = reshaped_input\n",
    "    transformer_block = tfa.layers.MultiHeadAttention(head_size=32, num_heads=4)([transformer_block, transformer_block, transformer_block])\n",
    "    transformer_block = Dense(32, activation='relu')(transformer_block)\n",
    "    transformer_block = Dropout(0.2)(transformer_block)\n",
    "    transformer_block = Flatten()(transformer_block)\n",
    "    output_layer = Dense(3, activation='softmax')(transformer_block)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "    model.fit(X_tr, y_tr, epochs=10, batch_size=64, verbose=0)\n",
    "\n",
    "    # 预测\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "    acc_per_fold.append(accuracy_score(y_val_classes, y_val_pred_classes))\n",
    "    precision_per_fold.append(precision_score(y_val_classes, y_val_pred_classes, average=None))\n",
    "    recall_per_fold.append(recall_score(y_val_classes, y_val_pred_classes, average=None))\n",
    "    f1_per_fold.append(f1_score(y_val_classes, y_val_pred_classes, average=None))\n",
    "\n",
    "# 转为数组\n",
    "precision_per_fold = np.array(precision_per_fold)\n",
    "recall_per_fold = np.array(recall_per_fold)\n",
    "f1_per_fold = np.array(f1_per_fold)\n",
    "\n",
    "# 打印每个类别的均值、标准差、95%置信区间\n",
    "\n",
    "def summarize_scores(scores, metric_name):\n",
    "    print(f\"\\n{metric_name} per class:\")\n",
    "    for i in range(scores.shape[1]):\n",
    "        mean = np.mean(scores[:, i])\n",
    "        std = np.std(scores[:, i])\n",
    "        ci95 = 1.96 * std / np.sqrt(scores.shape[0])\n",
    "        lower = mean - ci95\n",
    "        upper = mean + ci95\n",
    "        print(f\"Class {i}: Mean = {mean:.4f}, Std = {std:.4f}, 95% CI = [{lower:.4f}, {upper:.4f}]\")\n",
    "\n",
    "acc_mean = np.mean(acc_per_fold)\n",
    "acc_std = np.std(acc_per_fold)\n",
    "acc_ci95 = 1.96 * acc_std / np.sqrt(len(acc_per_fold))\n",
    "acc_lower = acc_mean - acc_ci95\n",
    "acc_upper = acc_mean + acc_ci95\n",
    "print(f\"\\nAccuracy: Mean = {acc_mean:.4f}, Std = {acc_std:.4f}, 95% CI = [{acc_lower:.4f}, {acc_upper:.4f}]\")\n",
    "\n",
    "summarize_scores(precision_per_fold, \"Precision\")\n",
    "summarize_scores(recall_per_fold, \"Recall\")\n",
    "summarize_scores(f1_per_fold, \"F1-Score\")\n",
    "\n",
    "# 用独立测试集评估\n",
    "# 定义最终模型\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "reshaped_input = Reshape((X_train.shape[1], 1))(input_layer)\n",
    "transformer_block = reshaped_input\n",
    "transformer_block = tfa.layers.MultiHeadAttention(head_size=32, num_heads=4)([transformer_block, transformer_block, transformer_block])\n",
    "transformer_block = Dense(32, activation='relu')(transformer_block)\n",
    "transformer_block = Dropout(0.2)(transformer_block)\n",
    "transformer_block = Flatten()(transformer_block)\n",
    "output_layer = Dense(3, activation='softmax')(transformer_block)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "model.fit(X_train, dummy_y_train, epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "# 测试集预测\n",
    "y_pred_2 = model.predict(X_test)\n",
    "y_pred_classes_2 = np.argmax(y_pred_2, axis=1)\n",
    "y_test_classes_2 = np.argmax(dummy_y_test, axis=1)\n",
    "\n",
    "# 测试集评估\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_classes_2, y_pred_classes_2))\n",
    "print(classification_report(y_test_classes_2, y_pred_classes_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(y_test_classes_2, y_pred_classes_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算指标\n",
    "num_classes = 3  # 假设有 3 个类别\n",
    "avg_fpr, avg_fdr, avg_for, avg_fnr = calculate_metrics_multiclass(y_test_classes_2, y_pred_classes_2, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tnr, avg_mcc, avg_npv = calculate_multiclass_tnr_mcc_npv(y_test_classes_2, y_pred_classes_2, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test_classes_2, y_pred_classes_2, \"Purples\",\"Transformer\",\"./Picture/transformer_juzehn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_test_classes_2, y_pred_2 , num_classes, \"purple\",\"Transformer\",\"./Picture/transformer_ROC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM-transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, LSTM, BatchNormalization, LayerNormalization, Flatten, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.metrics import Precision, Recall\n",
    "import numpy as np\n",
    "\n",
    "def transformer_block(x, head_size=32, num_heads=2, ff_dim=32, dropout=0.1):\n",
    "    # 多头注意力\n",
    "    attn_output = tfa.layers.MultiHeadAttention(head_size=head_size, num_heads=num_heads)([x, x, x])\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    # 残差连接 + LayerNorm\n",
    "    x = Add()([x, attn_output])\n",
    "    x = LayerNormalization()(x)\n",
    "    \n",
    "    # 前馈网络\n",
    "    ff_output = Dense(ff_dim, activation='relu')(x)\n",
    "    ff_output = Dense(x.shape[-1])(ff_output)  # 输出维度要跟输入一样，方便Add\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    # 残差连接 + LayerNorm\n",
    "    x = Add()([x, ff_output])\n",
    "    x = LayerNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# 重塑数据以适用于模型\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# 5折交叉验证\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc_per_fold = []\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "f1_per_fold = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train, y_train):\n",
    "    X_tr, X_val = X_train_reshaped[train_idx], X_train_reshaped[val_idx]\n",
    "    y_tr, y_val = dummy_y_train[train_idx], dummy_y_train[val_idx]\n",
    "\n",
    "    input_layer = Input(shape=(X_tr.shape[1], 1))\n",
    "\n",
    "    # BiLSTM层\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Transformer块\n",
    "    x = transformer_block(x, head_size=32, num_heads=2, ff_dim=64, dropout=0.1)\n",
    "\n",
    "    # Flatten层\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # 输出层\n",
    "    output_layer = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_tr, y_tr, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_classes = np.argmax(y_val, axis=1)\n",
    "\n",
    "    acc_per_fold.append(accuracy_score(y_val_classes, y_val_pred_classes))\n",
    "    precision_per_fold.append(precision_score(y_val_classes, y_val_pred_classes, average=None))\n",
    "    recall_per_fold.append(recall_score(y_val_classes, y_val_pred_classes, average=None))\n",
    "    f1_per_fold.append(f1_score(y_val_classes, y_val_pred_classes, average=None))\n",
    "\n",
    "# 转为数组\n",
    "precision_per_fold = np.array(precision_per_fold)\n",
    "recall_per_fold = np.array(recall_per_fold)\n",
    "f1_per_fold = np.array(f1_per_fold)\n",
    "\n",
    "def summarize_scores(scores, metric_name):\n",
    "    print(f\"\\n{metric_name} per class:\")\n",
    "    for i in range(scores.shape[1]):\n",
    "        mean = np.mean(scores[:, i])\n",
    "        std = np.std(scores[:, i])\n",
    "        ci95 = 1.96 * std / np.sqrt(scores.shape[0])\n",
    "        print(f\"Class {i}: Mean = {mean:.4f}, Std = {std:.4f}, 95% CI = [{(mean-ci95):.4f}, {(mean+ci95):.4f}]\")\n",
    "\n",
    "print(f\"\\nAccuracy: Mean = {np.mean(acc_per_fold):.4f}, Std = {np.std(acc_per_fold):.4f}, 95% CI = [{(np.mean(acc_per_fold)-1.96*np.std(acc_per_fold)/np.sqrt(len(acc_per_fold))):.4f}, {(np.mean(acc_per_fold)+1.96*np.std(acc_per_fold)/np.sqrt(len(acc_per_fold))):.4f}]\")\n",
    "summarize_scores(precision_per_fold, \"Precision\")\n",
    "summarize_scores(recall_per_fold, \"Recall\")\n",
    "summarize_scores(f1_per_fold, \"F1-Score\")\n",
    "\n",
    "# 用独立测试集评估\n",
    "input_layer = Input(shape=(X_train.shape[1], 1))\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = transformer_block(x, head_size=32, num_heads=2, ff_dim=64, dropout=0.1)\n",
    "x = Flatten()(x)\n",
    "output_layer = Dense(3, activation='softmax')(x)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "model.fit(X_train_reshaped, dummy_y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# 测试集预测\n",
    "y_pred_3 = model.predict(X_test_reshaped)\n",
    "y_pred_classes_3 = np.argmax(y_pred_3, axis=1)\n",
    "y_test_classes_3 = np.argmax(dummy_y_test, axis=1)\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_classes_3, y_pred_classes_3))\n",
    "print(classification_report(y_test_classes_3, y_pred_classes_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(y_test_classes_3, y_pred_classes_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算指标\n",
    "num_classes = 3  # 假设有 3 个类别\n",
    "avg_fpr, avg_fdr, avg_for, avg_fnr = calculate_metrics_multiclass(y_test_classes_3, y_pred_classes_3, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tnr, avg_mcc, avg_npv = calculate_multiclass_tnr_mcc_npv(y_test_classes_3, y_pred_classes_3, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test_classes_3, y_pred_classes_3, \"Blues\",\"BiLSTM-Transformer\",\"./Picture/BiLSTM-transformer_juzehn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_test_classes_3, y_pred_3 , num_classes, \"blue\",\"BiLSTM-Transformer\",\"./Picture/BiLSTM-Transformer_ROC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTM-transformer-对抗训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Bidirectional, LSTM, Flatten, BatchNormalization, LayerNormalization, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "# ------------- transformer_block函数 -------------\n",
    "def transformer_block(x, head_size=32, num_heads=2, ff_dim=32, dropout=0.1):\n",
    "    # 多头注意力\n",
    "    attn_output = tfa.layers.MultiHeadAttention(head_size=head_size, num_heads=num_heads)([x, x, x])\n",
    "    attn_output = Dropout(dropout)(attn_output)\n",
    "    # 残差连接 + LayerNorm\n",
    "    x = Add()([x, attn_output])\n",
    "    x = LayerNormalization()(x)\n",
    "\n",
    "    # 前馈网络\n",
    "    ff_output = Dense(ff_dim, activation='relu')(x)\n",
    "    ff_output = Dense(x.shape[-1])(ff_output)  # 输出维度要跟输入一样\n",
    "    ff_output = Dropout(dropout)(ff_output)\n",
    "    # 残差连接 + LayerNorm\n",
    "    x = Add()([x, ff_output])\n",
    "    x = LayerNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# ------------- GPU加速配置 -------------\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# ------------- 数据准备 -------------\n",
    "X = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "y = np.argmax(dummy_y_train, axis=1)\n",
    "\n",
    "# ------------- 定义模型函数 -------------\n",
    "def create_model():\n",
    "    input_layer = Input(shape=(X.shape[1], 1))\n",
    "    initializer = GlorotUniform(seed=1)\n",
    "\n",
    "    # BiLSTM\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True))(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # Transformer Block (换成你给的版本)\n",
    "    x = transformer_block(x, head_size=32, num_heads=2, ff_dim=64, dropout=0.2)\n",
    "\n",
    "    # Flatten和输出\n",
    "    x = Flatten()(x)\n",
    "    output_layer = Dense(3, activation='softmax', dtype=tf.float32)(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ------------- 对抗样本生成函数 -------------\n",
    "@tf.function\n",
    "def generate_adversarial_pgd(model, x, y, loss_fn, epsilon=0.001, alpha=0.0001, num_iter=10):\n",
    "    x_adv = tf.identity(x)\n",
    "    for _ in range(num_iter):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(x_adv)\n",
    "            prediction = model(x_adv, training=True)\n",
    "            loss = loss_fn(y, prediction)\n",
    "        gradients = tape.gradient(loss, x_adv)\n",
    "        x_adv = x_adv + alpha * tf.sign(gradients)\n",
    "        x_adv = tf.clip_by_value(x_adv, x - epsilon, x + epsilon)\n",
    "    return x_adv\n",
    "\n",
    "# ------------- 5折交叉验证 -------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "batch_size = 64\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nFold {fold+1}\")\n",
    "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "    y_train_fold, y_val_fold = dummy_y_train[train_idx], dummy_y_train[val_idx]\n",
    "\n",
    "    assert len(X_train_fold) == len(y_train_fold), \"训练集特征与标签数量不匹配\"\n",
    "    assert len(X_val_fold) == len(y_val_fold), \"验证集特征与标签数量不匹配\"\n",
    "\n",
    "    y_val_classes = np.argmax(y_val_fold, axis=1)\n",
    "    print(f\"数据验证: X_val={len(X_val_fold)}, y_val={len(y_val_classes)}\")\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train_fold, y_train_fold))\n",
    "    train_dataset = train_dataset.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    model = create_model()\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        print(f\"\\nEpoch {epoch+1}/5\")\n",
    "\n",
    "        if epoch < 4:\n",
    "            model.fit(\n",
    "                train_dataset,\n",
    "                epochs=1,\n",
    "                validation_data=(X_val_fold, y_val_fold),\n",
    "                callbacks=[early_stopping],\n",
    "                verbose=1\n",
    "            )\n",
    "        else:\n",
    "            print(\"Adversarial training phase...\")\n",
    "            total_samples = len(X_train_fold)\n",
    "            for i in range(0, len(X_train_fold), batch_size):\n",
    "                end_idx = min(i + batch_size, total_samples)\n",
    "                x_batch = X_train_fold[i:end_idx]\n",
    "                y_batch = y_train_fold[i:end_idx]\n",
    "\n",
    "                if len(x_batch) == 0:\n",
    "                    continue\n",
    "\n",
    "                tensor_x_batch = tf.convert_to_tensor(x_batch, dtype=tf.float32)\n",
    "                tensor_y_batch = tf.convert_to_tensor(y_batch, dtype=tf.float32)\n",
    "\n",
    "                adversarial_x_batch = generate_adversarial_pgd(model, tensor_x_batch, tensor_y_batch, loss_fn)\n",
    "\n",
    "                mixed_x_batch = tf.concat([tensor_x_batch, adversarial_x_batch], axis=0)\n",
    "                mixed_y_batch = tf.concat([tensor_y_batch, tensor_y_batch], axis=0)\n",
    "\n",
    "                model.fit(\n",
    "                    mixed_x_batch, mixed_y_batch,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=1,\n",
    "                    verbose=1\n",
    "                )\n",
    "\n",
    "    y_pred_4 = model.predict(X_val_fold, verbose=0)\n",
    "    assert len(y_pred_4) == len(X_val_fold), \"预测结果数量异常\"\n",
    "\n",
    "    y_pred_classes_4 = np.argmax(y_pred_4, axis=1)\n",
    "    assert len(y_pred_classes_4) == len(y_val_classes), f\"样本数不匹配: {len(y_pred_classes_4)} vs {len(y_val_classes)}\"\n",
    "\n",
    "    acc_list.append(accuracy_score(y_val_classes, y_pred_classes_4))\n",
    "    precision_list.append(precision_score(y_val_classes, y_pred_classes_4, average=None))\n",
    "    recall_list.append(recall_score(y_val_classes, y_pred_classes_4, average=None))\n",
    "    f1_list.append(f1_score(y_val_classes, y_pred_classes_4, average=None))\n",
    "\n",
    "# ------------- 修改后的结果统计函数 -------------\n",
    "def summarize(name, scores):\n",
    "    scores = np.array(scores)\n",
    "    mean = np.mean(scores, axis=0)\n",
    "    std = np.std(scores, axis=0)\n",
    "    lower = mean - 1.96 * std / np.sqrt(scores.shape[0])\n",
    "    upper = mean + 1.96 * std / np.sqrt(scores.shape[0])\n",
    "\n",
    "    for i in range(len(mean)):\n",
    "        print(f\"{name} Class {i}: {mean[i]:.4f}, Std={std[i]:.4f}, (95% CI: [{lower[i]:.4f}, {upper[i]:.4f}])\")\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "summarize(\"Accuracy\", [np.array([a, a, a]) for a in acc_list])\n",
    "summarize(\"Precision\", precision_list)\n",
    "summarize(\"Recall\", recall_list)\n",
    "summarize(\"F1\", f1_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(y_test_classes_4, y_pred_classes_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算指标\n",
    "num_classes = 3  # 假设有 3 个类别\n",
    "avg_fpr, avg_fdr, avg_for, avg_fnr = calculate_metrics_multiclass(y_test_classes_4, y_pred_classes_4, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tnr, avg_mcc, avg_npv = calculate_multiclass_tnr_mcc_npv(y_test_classes_4, y_pred_classes_4, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test_classes_4, y_pred_classes_4, \"Greens\",\"BiLSTM-Transformer-adv\",\"./Picture/BiLSTM-transformer-adv_juzehn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc(y_test_classes_4, y_pred_4 , num_classes, \"green\",\"BiLSTM-Transformer-adv\",\"./Picture/BiLSTM-transformer-adv_ROC.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycharm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
